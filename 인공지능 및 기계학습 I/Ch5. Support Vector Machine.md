# 5.1. Decision Boundary with Margin

ì•ì„œì„œ Decision boundaryë¥¼ ê²°ì •í•˜ëŠ” ì—¬ëŸ¬ í™•ë¥ ë¡ ì  ë°©ë²•ë“¤ì— ëŒ€í•´ ë°°ì› ì—ˆëŠ”ë°,

ì²«ë²ˆì§¸ë¡œ, Bayes Riskë¥¼ í™œìš©í•œ ë°©ë²•ì´ ìˆì—ˆë‹¤.

![image](https://user-images.githubusercontent.com/101063108/160315868-171f21c6-7b26-465a-9ce7-a86a422bce3c.png)

ë¹¨ê°„ ì„ ê³¼ ì´ˆë¡ ì„ ì´ êµì°¨í•˜ëŠ” ë¶€ë¶„ì´ decision boundaryê°€ ëœë‹¤.

ë‘ë²ˆì§¸ë¡œ, 2ì°¨ì›ì—ì„œì˜ decision boundaryë¥¼ ê²°ì •í•˜ëŠ” ê²ƒì´ ìˆëŠ”ë°, ì´ëŠ” Naive Baysesë¥¼ ì´ìš©í•˜ì—¬ classifyí•´ ì£¼ì—ˆë‹¤.

![image](https://user-images.githubusercontent.com/101063108/160316062-d7dcb545-f78c-4dc3-9bc2-727dafa949d4.png)

ìœ„ì˜ ë‘ ê²½ìš° ëª¨ë‘ **í™•ë¥ **ì— ì˜ì¡´í•œ decision boundaryì˜ ê²°ì •ì´ë‹¤.

ê·¸ë ‡ë‹¤ë©´ í™•ë¥  ì—†ì´ decision boundaryë¥¼ ì°¾ì„ ìˆ˜ ìˆì„ê¹Œ?

![image](https://user-images.githubusercontent.com/101063108/160316233-100b2395-320d-4e96-952d-892960f3beb2.png)

ì´ëŸ° instanceë“¤ì´ ìˆë‹¤ê³  ê°€ì •í•´ë³´ì. 

ì´ ê²½ìš°, decision boundaryë¥¼ ì•„ë˜ì™€ ê°™ì´ ì„¤ì •í–ˆì„ ë•Œ ì–´ë–¤ê²Œ bestí•œê°€?

![image](https://user-images.githubusercontent.com/101063108/160316432-c8ead086-8705-4219-8cb1-89af12d7275d.png)

ì—°ë‘ìƒ‰ ì„ ê³¼ ì£¼í™©ìƒ‰ ì„ ì˜ ê²½ìš° ì„ ì— ê·¼ì ‘í•œ caseë“¤ì´ ì˜¤ë¥˜ë¥¼ ë²”í•  í™•ë¥ ì´ ì¦ê°€í•œë‹¤. 

ë”°ë¼ì„œ í•˜ëŠ˜ìƒ‰ ì„ ì´ ê°€ì¥ ì ì ˆí•˜ë‹¤ê³  ë³¼ ìˆ˜ ìˆë‹¤.

ì´ëŸ¬í•œ ê±°ë¦¬ë¥¼ ìµœëŒ€ë¡œ í•  ìˆ˜ ìˆëŠ” ê²½ìš°, decision boundaryë¥¼ ì„¤ì •í•  ìˆ˜ ìˆë‹¤.

![image](https://user-images.githubusercontent.com/101063108/160316923-7b000003-c852-42bb-86d6-dc09cba2c84e.png)

ìœ„ ê·¸ë¦¼ì—ì„œ ë³´ë©´, ê²½ê³„ì— ê°€ì¥ ê°€ê¹Œìš´ ë¹¨ê°„ ì  ë‘ê°œë¥¼ ì§€ë‚˜ëŠ” ì§ì„ ì„ ê·¸ë¦¬ê³ , ê·¸ ì§ì„ ì„ í‰í–‰í•˜ê²Œ ê²½ê³„ì— ê°€ì¥ ê°€ê¹Œìš´ íŒŒë€ ì ê¹Œì§€ ë‚´ë ¤ì£¼ì–´, í•œê³„ì¹˜ë¥¼ ì„¤ì •í•´ì¤€ë‹¤.

ê·¸ í›„ ê·¸ ë‘ ì§ì„ ì˜ ì¤‘ê°„ ì§€ì ì— í‰í–‰í•œ ì§ì„ ì„ ê·¸ë¦¬ë©´, ê·¸ê²ƒì´ decision boundaryê°€ ëœë‹¤.

ì´ë•Œ, decision boundaryì™€ í•œê³„ì— ìœ„ì¹˜í•œ ì§ì„ ì‚¬ì´ì˜ ê±°ë¦¬ë¥¼ Marginì´ë¼ê³  í•œë‹¤.

(ì •í™•í•˜ê²Œ ì´ì•¼ê¸°í•˜ìë©´, decision boundaryì™€ ê°€ì¥ ê°€ê¹Œìš´ ì  ì‚¬ì´ì˜ ê±°ë¦¬ì´ë‹¤.)

ì—¬ê¸°ì„œ ì´ decision boundaryë¥¼ ê²°ì •ì§“ëŠ” point 3ê°œë¥¼ ì°¾ëŠ” ê²ƒì´ í•µì‹¬ì´ ëœë‹¤.

*support vector machineì€ ì´ëŸ¬í•œ ì (ë²¡í„°)ë“¤ì´ decision boundaryë¥¼ ê²°ì •í•˜ê¸° ìœ„í•´ supportí•´ì¤€ë‹¤ëŠ” ì˜ë¯¸*

decision boundary lineì€ ì•„ë˜ì™€ ê°™ì´ ì •ì˜í•  ìˆ˜ ìˆë‹¤.

* **w Â· x** + b = 0

wëŠ” x1ê³¼ x2ë¼ëŠ” ë‘ê°œì˜ ë§¤ê°œë³€ìˆ˜ë¥¼ ê°€ì§€ëŠ” ë²¡í„°ë¡œ í‘œí˜„, bëŠ” ì ˆí¸

-> ì´ 3ê°œì˜ ë§¤ê°œë³€ìˆ˜ê°€ í•„ìš”í•˜ë‹¤.

* positive case
    * **w Â· x** + b > 0
* negative case
    * **w Â· x** + b < 0
* confidence level
    * (**w Â·** ğ±ğ’‹ + b)ğ‘¦ğ‘—

ì´ë•Œ confidence levelì„ ìµœëŒ€í™”í•˜ëŠ” ê²ƒì´ ì ì ˆí•œ decision boundaryë¥¼ ì„¤ì •í•˜ëŠ” ë°©ë²•ì´ë‹¤.

# 5.2. Maximizing the Margin

f(x) = **w Â· x** + b ë¼ê³  í•˜ì.

![image](https://user-images.githubusercontent.com/101063108/160327833-aa86dc37-f291-490e-99f3-68dbac3e843c.png)

ì  xê°€ boundary ìœ„ì— ìˆë‹¤ë©´, f(x) = **w Â· x** + b = 0

ì–‘ì˜ ì  xë¼ë©´, f(x) = **w Â· x** + b = a, a>0

ì„ì˜ì˜ ì  xì—ì„œ decision boundary ìœ„ë¡œ ìˆ˜ì„ ì˜ ë°œì„ ë‚´ë¦° ì ì„ ![image](https://user-images.githubusercontent.com/101063108/160341634-af05dedb-3103-4fe5-8332-fc52c5f30efb.png)ë¼ í•˜ì.

ê·¸ ë‘˜ ì‚¬ì´ì˜ ê±°ë¦¬ë¥¼ ì¬ë³¼í…ë°, ì´ ê±°ë¦¬ë¥¼ rì´ë¼ í•˜ê³ , wëŠ” decision boundaryì— ìˆ˜ì§ì¸ ë²¡í„° (1,-1)ì´ë¼ í•˜ë©´,

![image](https://user-images.githubusercontent.com/101063108/160345653-7cf5d1af-00f7-42c5-ba36-f8a917a1c3c3.png)

wë²¡í„°ë¥¼ wë²¡í„°ì˜ í¬ê¸°ë¡œ ë‚˜ëˆ ì£¼ë©´ ë‹¨ìœ„ë²¡í„°ê°€ ëœë‹¤.

![image](https://user-images.githubusercontent.com/101063108/160345779-2f6c6053-7550-4700-9205-7728edeb3316.png)

ì´ë•Œ ![image](https://user-images.githubusercontent.com/101063108/160345887-7ef0cbb8-d80b-43c9-8425-74eb0b0a2a23.png)ëŠ” ìœ„ì˜ ì‹ì—ì„œ 0ì´ë¯€ë¡œ, ìœ„ì™€ ê°™ì´ ê³„ì‚°ëœë‹¤.

ë”°ë¼ì„œ ê±°ë¦¬ rì€ ë‹¤ìŒê³¼ ê°™ë‹¤.

![image](https://user-images.githubusercontent.com/101063108/160345995-e3554d7d-f7a9-4a77-ad68-9dfad8420748.png)

ê·¸ë ‡ë‹¤ë©´ ì¢‹ì€ decision boundaryëŠ” margin distanceë¥¼ ì–´ë–»ê²Œ í•´ì•¼í• ê¹Œ?

marginì„ ìµœëŒ€í™”í•´ì•¼ í•œë‹¤.

ì—¬ê¸°ì„œ ì ê³¼ decision boundary ì‚¬ì´ì˜ ê±°ë¦¬ê°€ r, ì¦‰ ìœ„ì˜ ì‹ê³¼ ê°™ë‹¤.

![image](https://user-images.githubusercontent.com/101063108/160351175-aa0e8a97-8e3d-487f-93ef-31159656adf6.png)

ì´ë•Œ, ì•„ë˜ìª½ í•œê³„ì™€ ìœ„ìª½ í•œê³„ ë‘˜ë‹¤ ê³ ë ¤í•´ì£¼ì–´ì•¼ í•˜ë¯€ë¡œ 2rì„ ìµœëŒ€í™” í•˜ê³ ì í•œë‹¤.

![image](https://user-images.githubusercontent.com/101063108/160351361-93ad5649-ef8a-4399-b318-264ef2b89b01.png)

ìš°ë¦¬ëŠ” margin distanceë¥¼ êµ¬í•˜ê³  ìˆìœ¼ë¯€ë¡œ, ëª¨ë“  instanceì— ëŒ€í•´ aë³´ë‹¤ í¬ê±°ë‚˜ ê°™ì•„ì•¼í•œë‹¤.

aëŠ” ì„ì˜ì˜ ìˆ«ì ì´ë¯€ë¡œ 1ì„ ë„£ì–´ë³´ë©´,

![image](https://user-images.githubusercontent.com/101063108/160352301-3b2f648f-b018-480e-a88f-0833df7a9912.png)

ìœ„ì˜ ì‹ì²˜ëŸ¼ ë˜ê³ , 2ëŠ” ìƒìˆ˜ì´ë¯€ë¡œ ìµœëŒ€í™”í•˜ëŠ”ë° ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•Šìœ¼ë¯€ë¡œ 1ë¡œ ë°”ê¿”ë„ ë¬´ë°©í•˜ë‹¤.

wê°€ ë¶„ëª¨ì— ìˆì–´ ê³„ì‚°í•˜ê¸° ê¹Œë‹¤ë¡œìš°ë¯€ë¡œ, ìµœì†Œí™”í•˜ëŠ” ê²ƒìœ¼ë¡œ ì‹ì„ ë°”ê¿”ì¤€ë‹¤.

![image](https://user-images.githubusercontent.com/101063108/160352676-acebb40a-2d10-4156-9d3a-08bbdc6e3be0.png)

ì´ë•Œ ![image](https://user-images.githubusercontent.com/101063108/160353160-9a82e026-d077-4b9b-853e-1325610c886e.png)
ëŠ” ![image](https://user-images.githubusercontent.com/101063108/160353184-f717d8c6-d82a-4370-a7fd-0462d587e8f2.png) ìœ¼ë¡œ ì“¸ ìˆ˜ ìˆê³ , ë£¨íŠ¸ì˜ ê²½ìš° ì—°ì†ì ìœ¼ë¡œ ì¦ê°€í•˜ê¸° ë•Œë¬¸ì— ìµœì†Œí™”í•˜ëŠ”ë°ì— ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•ŠëŠ”ë‹¤.

ë”°ë¼ì„œ ì•ˆì˜ ë‚´ìš©ì´ ì¤‘ìš”í•´ì§€ëŠ”ë° ì´ ì œê³±ì˜ í˜•íƒœê°€ ìˆì–´ì„œ ì´ê²ƒì´ quadratic optimization ë¬¸ì œê°€ ëœë‹¤.

linear programmingì„ ì´ìš©í•˜ê±°ë‚˜, quadratic programmingì„ ì´ìš©í•´ ìµœì í™”ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆë‹¤.

# 5.3. SVM with Matlab

//matlab ì‹¤ìŠµ

ìš°ë¦¬ê°€ ì§€ê¸ˆê¹Œì§€ í•´ì™”ë˜ ê²ƒì€ ë¶„ë¥˜ê°€ ì˜ ë˜ì–´ ìˆëŠ” ê²½ìš° ì˜€ë‹¤. í•˜ì§€ë§Œ ì‹¤ì œë¡œëŠ” ê·¸ë ‡ì§€ ì•Šì€ ê²½ìš°ê°€ ë§ì„ ê²ƒì´ë‹¤.

![image](https://user-images.githubusercontent.com/101063108/160525663-163b30eb-7639-441d-8a3b-ebf7dfe1f1d3.png)

ë§Œì¼ ìƒˆë¡œìš´ ì ë“¤ì´ ì¶”ê°€ ëœë‹¤ê³  í•˜ë©´, Decision boundaryë„ ë³€ê²½ë  ê²ƒì´ë‹¤.

![image](https://user-images.githubusercontent.com/101063108/160525740-bdd5104d-a3e4-4265-b62f-914da005e4c9.png)

ìœ„ì˜ ë‘ê°œì˜ ì ì´ë¼ë©´, marginì´ ì¤„ì–´ë“¤ê¸´ í•´ë„ ì„ í˜•ìœ¼ë¡œ decision boundaryë¥¼ ê²°ì •í•  ìˆ˜ ìˆì„ ê²ƒì´ë‹¤.

ê·¸ëŸ¬ë‚˜ ë¶„ë¥˜ë¥¼ ì–´ë µê²Œ í•˜ëŠ” ì ì´ ë“¤ì–´ì˜¨ë‹¤ë©´, ì„ í˜•ìœ¼ë¡œëŠ” ë¶„ë¥˜ë¥¼ í•  ìˆ˜ ì—†ëŠ” ê²½ìš°ê°€ ìƒê¸´ë‹¤.

ìš°ë¦¬ëŠ” ê·¸ë™ì•ˆ Hard marginì„ ì´ìš©í•´ì™”ë‹¤.

Hard marginì´ë€, ì—ëŸ¬ ì¼€ì´ìŠ¤ë¥¼ í—ˆìš©í•˜ì§€ ì•ŠëŠ” ê²ƒì´ë‹¤. ë°˜ëŒ€ë¡œ Soft marginì€ ì§€ì •í•œ ì—ëŸ¬ì¼€ì´ìŠ¤ëŠ” í—ˆìš©í•˜ê² ë‹¤ ë¼ëŠ” ì˜ë¯¸ì´ë‹¤.

ì´ëŸ¬í•œ soft marginì„ ì´ìš©í•´ ì´ ë¬¸ì œë¥¼ í•´ê²°í•  ìˆ˜ ìˆê³ , ë˜ëŠ” kernel trickì„ ì´ìš©í•´ hard marginì´ì§€ë§Œ decision boundaryê°€ ì„ í˜•ì´ ì•„ë‹Œ ë°©ì‹ìœ¼ë¡œ í•´ê²°í•  ìˆ˜ ìˆì„ ê²ƒì´ë‹¤.

# 5.4. Error Handling in SVM

ì´ëŸ¬í•œ ì„ í˜•ì ì¸ decision boundaryë¡œ ë¶„ë¥˜í•  ìˆ˜ ì—†ëŠ” ì—ëŸ¬ ì¼€ì´ìŠ¤ê°€ ë°œìƒí–ˆì„ ë•Œ ì–´ë–»ê²Œ í•´ì•¼í• ê¹Œ?

![image](https://user-images.githubusercontent.com/101063108/160537164-0d60b885-b37c-4167-9d92-4e007b408de0.png)


1. decision boundaryë¥¼ ë” ë³µì¡í•˜ê²Œ ë§Œë“¤ì.

ê·¸ë ‡ê²Œ ë˜ë©´ ì´ì œ non-linearí•˜ê²Œ ëœë‹¤.

2. errorê°€ ìˆìŒì„ ì¸ì •í•˜ì.

ì´ëŸ¬í•œ ì—ëŸ¬ë¥¼ ì‹ì— ì ìš©í•˜ê³ , ì´ ì—ëŸ¬ë¥¼ ì˜ ì¤„ì´ëŠ” ê²ƒì´ ì¤‘ìš”í•´ì§„ë‹¤.

ì—ëŸ¬ê°€ ìˆìŒì„ ì¸ì •í•  ë•Œ, ì–´ë–»ê²Œ ë‹¤ë£¨ì–´ì•¼ í• ê¹Œ?

![image](https://user-images.githubusercontent.com/101063108/160537902-04e11df5-ead0-4085-ac81-c21e5c324e75.png)


1. ì—ëŸ¬ ì¼€ì´ìŠ¤ì˜ ê°œìˆ˜ë¥¼ ì„¸ì„œ, ê·¸ ìˆ˜ë¥¼ ì¤„ì´ëŠ” ë°©ë²•

![image](https://user-images.githubusercontent.com/101063108/160537274-a26fb113-b26e-4ef9-85e2-a9c5964bc661.png)

CëŠ” ì •ë„ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ìƒìˆ˜, 1ì´ë¼ê³  ë‘˜ ìˆ˜ ìˆë‹¤. Cë¥¼ 1ì´ë¼ ë‘ë©´, ì—ëŸ¬ ì¼€ì´ìŠ¤ë“¤ì€ ë©€ë“  ê°€ê¹ë“  ëª¨ë‘ 1ì´ë¼ëŠ” ê°’ì„ ê°€ì§€ê²Œ ëœë‹¤.

íŒŒë€ìƒ‰ ì  ë¶€ë¶„ì´ positiveí•˜ë‹¤ê³  ê°€ì •í•˜ê³ , íŒŒë€ ì  í•˜ë‚˜ê°€ ì ì  decision boundary ìª½ìœ¼ë¡œ ì´ë™í•˜ë‹¤ê°€ ë„˜ì–´ê°€ì„œ error caseê°€ ëœë‹¤ê³  í•´ë³´ì.

ì´ ì ì´ íŒŒë€ ì„ ì— ë‹¿ëŠ” ìˆœê°„ ìš°ë¦¬ê°€ ì „ì— ë§í•œ aë¼ëŠ” ê°’ì´ 1ì´ ë˜ê³ , ê±°ê¸°ì„œë¶€í„° ì—ëŸ¬ì˜ ê°€ëŠ¥ì„±ì€ ì˜¬ë¼ê°€ê²Œ ëœë‹¤.

ê·¸ëŸ¬ë‹¤ê°€ decision boundaryë¥¼ ë„˜ëŠ” ìˆœê°„ ì´ ì¼€ì´ìŠ¤ëŠ” ì´ì œ ì—ëŸ¬ê°€ ë˜ë¯€ë¡œ ì—ëŸ¬ë¥¼ ë‚˜íƒ€ë‚´ëŠ” loss functionì€ 0ì—ì„œ 1ë¡œ ì í”„í•˜ê²Œ ëœë‹¤.

ì´ëŸ¬í•œ ë°©ì‹ì€ í˜„ì¬ëŠ” ì˜ ì‚¬ìš©ë˜ì§€ ì•ŠëŠ”ë°, ë©€ê±°ë‚˜ ê°€ê¹ê±°ë‚˜ ìƒê´€ì—†ì´ error ì¼€ì´ìŠ¤ê°€ ë‹¤ 1ì´ë¼ëŠ” penaltyë¥¼ ë°›ê²Œ ë˜ê¸° ë•Œë¬¸ì´ê¸°ë„ í•˜ë‹¤.

2. Hinge lossì˜ ì´ìš©

ì´ëŸ¬í•œ ê²ƒì„ ë³´ì™„í•œê²ƒì´ hinge lossì´ë‹¤.

hinge lossëŠ” slack ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ëª» ë¶„ë¥˜ëœ caseì— ëŒ€í•´ ê°ê¸° ë‹¤ë¥¸ penaltyë¥¼ ë¶€ê³¼í•œë‹¤.

![image](https://user-images.githubusercontent.com/101063108/160538157-db955979-71a8-4459-b847-1fd05620f84e.png)

![image](https://user-images.githubusercontent.com/101063108/160538175-1cd9a244-9251-4ccc-bf8c-c74c118a18b5.png)

ì‹ì—ì„œëŠ” ëª¨ë“  slackë³€ìˆ˜ë¥¼ ë”í•œ ê°’ì´ ë“¤ì–´ê°€ê²Œ ëœë‹¤.

ì—¬ê¸°ì„œ CëŠ” ìƒìˆ˜ê°€ ì•„ë‹Œ, ì •ë„ê°€ ë‹¤ë¥¸ ë§¤ê°œë³€ìˆ˜ê°€ ëœë‹¤.

a = 1ì´ ë˜ëŠ” ì‹œì ë¶€í„° ì„œì„œíˆ ì¦ê°€í•˜ê¸° ì‹œì‘í•˜ë©°, decision boundaryë¥¼ ì§€ë‚˜ëŠ” ìˆœê°„ 1ì´ ë˜ê³  ê·¸ í›„ëŠ” ê·¸ ì´ìƒì´ ëœë‹¤.

ì¡°ê±´ ë˜í•œ ë’¤ì— ![image](https://user-images.githubusercontent.com/101063108/160538606-5e54fef4-7615-4fe0-9c3f-c029df749402.png) ì´ê²ƒ ë§Œí¼ì´ ë˜ëŠ” slackì´ ë¶™ì„ ìˆ˜ ìˆë‹¤ëŠ” ê²ƒìœ¼ë¡œ ë°”ë€ë‹¤.

ì—¬ê¸°ì„œì˜ ë¬¸ì œëŠ” Cê°€  ë§¤ê°œë³€ìˆ˜ì´ê¸° ë•Œë¬¸ì— Cì˜ ê°’ì„ ì •í•´ì¤˜ì•¼ í•œë‹¤ëŠ” ê²ƒì´ë‹¤.

# 5.5. Soft Margin with SVM

![image](https://user-images.githubusercontent.com/101063108/160541790-7f4962d2-bcb4-426a-b9b3-5bde6bee92a7.png)

slack ë³€ìˆ˜ë¥¼ ì¶”ê°€í•˜ì—¬ penaltyë¥¼ ì¤„ ìˆ˜ ìˆëŠ”ë°, decision boundaryë¥¼ ë„˜ì–´ê°€ë©´ penaltyê°€ 1 ì´ìƒì˜ ê°’ì„ ê°€ì§€ê²Œ ëœë‹¤. 

penalizeë¥¼ í•˜ëŠ” functionì€ ë‹¤ìŒê³¼ ê°™ì´ slackì„ ì´ í•©í•˜ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆë‹¤.

![image](https://user-images.githubusercontent.com/101063108/160542258-72c4dfd4-e7e4-4d14-a900-6ce7905e3e3a.png)

penaltyì˜ ì •ë„ë¥¼ ê²°ì •í•˜ëŠ” ì´ Cë¥¼ ì •í•˜ëŠ”ê²Œ ì¤‘ìš”í•´ì§„ë‹¤.

**Log Loss**

![image](https://user-images.githubusercontent.com/101063108/160544788-78ce3e5d-d60e-4eba-87b0-16e21f2d7c8f.png)

logistic regressionì„ ì´ìš©í•´ loss functionì„ ë§Œë“¤ ìˆ˜ ìˆëŠ”ë°, ì´ë¥¼ log lossë¼ê³  í•œë‹¤.

![image](https://user-images.githubusercontent.com/101063108/160544988-200eeee1-0c16-4c0c-b1b5-bab05599ec4c.png)

![image](https://user-images.githubusercontent.com/101063108/160545024-2d0bdea8-3d9c-499e-8df9-60786770ce4f.png)

ì˜ˆì „ì— í–ˆë˜ ì‹ì„ ì ìš©ì‹œí‚¤ë©´,  hinge lossì˜ ![image](https://user-images.githubusercontent.com/101063108/160545181-02a2438a-9bc9-4083-97f3-90e26a0c29de.png) ì‹ê³¼ êµ¬ì¡°ê°€ ë¹„ìŠ·í•¨ì„ ì•Œ ìˆ˜ ìˆë‹¤.

ì„¸ê°œì˜ loss function (zero-one loss, hinge loss, log loss) ì¤‘ ì–´ë–¤ ê²ƒì´ ê°€ì¥ ì„ í˜¸ë ê¹Œ?

hinge lossê°€ 1ë¶€í„° penaltyê°€ ì¦ê°€í•˜ëŠ” ê²ƒìœ¼ë¡œ ë³´ì´ëŠ” ê²ƒì— ë°˜í•´ log lossë¥¼ ë³´ë©´ ì´ë¯¸ penaltyê°’ì„ ê°€ì§€ê³  ìˆëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. decision boundaryë¥¼ ì§€ë‚œ í›„ë¶€í„°ì˜ penaltyë¥¼ ë³´ë©´, hinge lossì— ë¹„í•´ ì™„ë§Œí•˜ê²Œ ì¦ê°€í•˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.

ê·¸ë ‡ë‹¤ë©´ CëŠ” ì–´ë–»ê²Œ ì •í•˜ëŠ”ê²Œ ì¢‹ì„ê¹Œ?

![image](https://user-images.githubusercontent.com/101063108/160546051-18db529e-5a77-4f2e-a5a3-df7c35938833.png)

ì•„ë˜ ê·¸ë¦¼ì„ ë³´ë©´ ì•Œ ìˆ˜ ìˆë“¯ì´, Cì˜ í¬ê¸°ê°€ ë„ˆë¬´ ì‘ì„ ê²½ìš°ì—ëŠ” penaltyê°€ ë„ˆë¬´ ì‘ì•„ì§€ë¯€ë¡œ ì œëŒ€ë¡œëœ decision boundaryë¥¼ ì„¤ì •í•  ìˆ˜ ì—†ë‹¤. ì¼ì • í¬ê¸°ì´ìƒì˜ CëŠ” decision boundaryì˜ ìœ„ì¹˜ê°€ ê±°ì˜ ë³€í•˜ì§€ ì•ŠëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

# 5.6. Rethinking of SVM

![image](https://user-images.githubusercontent.com/101063108/160550511-09279757-daa4-4ff1-9342-d56bf0d77aa6.png)

ì§€ê¸ˆê¹Œì§€ëŠ” error caseë¥¼ ì¸ì •í•˜ê³ , ìµœì†Œí•œì˜ ì—ëŸ¬ë¥¼ ë§Œë“œëŠ” soft marginì— ëŒ€í•´ ë‹¤ë¤˜ë‹¤ë©´, ì´ì œëŠ” ë” ë³µì¡í•œ decision boundaryë¥¼ í†µí•´ error caseë¥¼ ë§Œë“¤ì§€ ì•ŠëŠ” ë°©ë²•ì„ ì´ìš©í•˜ê³ ì í•œë‹¤.

ì´ëŸ¬í•œ ë³µì¡í•œ decision boundaryë¥¼ ì„¤ì •í•˜ê¸° ì „ì—, ê°€ì§€ê³  ìˆëŠ” ë°ì´í„°ë“¤ì´ ì–´ë–¤ ë°©ë²•ì— ì í•©í•œì§€ ë¨¼ì € íŒë‹¨í•˜ëŠ” ê³¼ì •ì´ í•„ìš”í•˜ë‹¤. 

![image](https://user-images.githubusercontent.com/101063108/160551493-d636e9b4-2394-478f-91d7-ba0904a91d31.png)

linearí•œ decision boundaryë¥¼ ê²°ì •í•˜ê¸° ìœ„í•œ ê·¸ë¦¼ì´ë‹¤. ì´ëŸ° ì‚¬ë¡€ì—ì„œëŠ” ëª…í™•í•˜ê²Œ ë¶„ë¥˜ê°€ ë˜ëŠ” hard marginì´ì§€ë§Œ, ì•„ë˜ì˜ ê·¸ë¦¼ì„ ë³´ì.

![image](https://user-images.githubusercontent.com/101063108/160551736-78136915-13b4-4a27-b6ab-76f3187858ad.png)

ì´ëŸ¬í•œ ê²½ìš°ì—ì„œëŠ” ìœ„ì™€ ê°™ì€ ë°©ë²•ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ë‹¤. ë” ë³µì¡í•œ, non-linearí•œ decision boundaryê°€ í•„ìš”í•˜ë‹¤.

ë”°ë¼ì„œ ìš°ë¦¬ëŠ” ì „ì— linear regressionì—ì„œ ì°¨ìˆ˜ë¥¼ ë†’ì—¬ì„œ ê³„ì‚°í–ˆë˜ ê²ƒì²˜ëŸ¼, ì£¼ì–´ì§„ x1, x2ë¥¼ ì¡°í•©í•´ ì°¨ì›ë¥¼ ë†’ì—¬ ë„£ì–´ë³¼ ê²ƒì´ë‹¤.

![image](https://user-images.githubusercontent.com/101063108/160552581-0d6ce1c0-36f9-49b8-b153-3a0d2c3d191a.png)

ê·¸ë ‡ê²Œ í•˜ë©´ ì˜¤ë¥¸ìª½ê³¼ ê°™ì€ ê·¸ë¦¼ì´ ë‚˜ì˜¤ê³ , ì—°ë‘ìƒ‰ ë¶€ë¶„ì„ ë”°ë¼ decision boundaryê°€ í˜•ì„±ëœ ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.

ì—¬ê¸°ì„œëŠ” 3ì°¨ê¹Œì§€ ë†’ì—¬ì„œ ë„£ì–´ë³´ì•˜ëŠ”ë°, ì´ê²ƒì„ ë¬´í•œëŒ€ê¹Œì§€ ëŠ˜ë¦¬ê¸° ìœ„í•´ì„œëŠ” kernel trickì„ ì‚¬ìš©í•´ì•¼í•œë‹¤.

kernel trickì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” SVMì— ìˆëŠ” primal ë¬¸ì œë¥¼ dual ë¬¸ì œë¡œ ë°”ê¾¸ì–´ì•¼í•œë‹¤.

SVMì€ Constrained quadratic programmingì„ ì´ìš©í•´ì„œ parameterë¥¼ ì¶”ë¡ í–ˆë‹¤.

Constrained optimization 

![image](https://user-images.githubusercontent.com/101063108/160554390-81756d97-4c97-40fd-b758-b78429295887.png)


**Lagrange method**

![image](https://user-images.githubusercontent.com/101063108/160554500-0cd0c849-72c8-4fb4-b1ac-cfe8557b4b6c.png)

optimize ë˜ì–´ìˆëŠ” Lagrangeì˜ prime functionì€ f(x)ì™€ ë™ì¼í•˜ê²Œ ì‘ë™í•œë‹¤.

ê·¸ë ‡ê²Œ ë˜ë©´, f(x)ë¥¼ ì“°ì§€ ì•Šê³  ìœ„ì˜ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤ : primal problem -> dual problem

# 5.7. Primal and Dual with KKT Condition

![image](https://user-images.githubusercontent.com/101063108/160765925-3f946193-bd07-48eb-b1c6-4f7d987bf6bd.png)

primal problemê³¼ lagrange dual problemì€ ìœ„ì™€ ê°™ìœ¼ë©°, ì•ì—ì„œì˜ lagrange methodì™€ ê´€ë ¨í•˜ì—¬ ì„¤ëª…ë  ìˆ˜ ìˆë‹¤.

**strong duality**

dual problemì˜ solutionê³¼ primal problemì˜ solutionì´ ê°™ì•„ì•¼ í•œë‹¤.

![image](https://user-images.githubusercontent.com/101063108/160766592-e7a9f00c-78f2-4377-87ed-6b390ee24e2e.png)

ì´ëŸ¬í•œ strong dualityë¥¼ ë³´ì¥í•´ì£¼ëŠ” ê²ƒì´ ìˆëŠ”ë° Karush-Kunh-Tucker (KKT) ì¡°ê±´ì„ ë§Œì¡±ì‹œí‚¤ëŠ” ê²ƒì´ë‹¤.

ì—¬ê¸°ì„œëŠ” dual problemìœ¼ë¡œ ë„˜ì–´ê°ˆ ë•Œ, KKT conditionì´ ë§Œì¡±ëœë‹¤ê³  ê°ì•ˆí•˜ê³  ë„˜ì–´ê°€ì.

ì§„ì§œ ì´ íŒŒíŠ¸ ë­” ë§ì¸ì§€ ì´í•´ì•ˆë˜ë‹ˆê¹Œ ë‚˜ì¤‘ì— ë‹¤ì‹œ ì •ë¦¬..

# 5.8. Kernel

**Mapping Function**

![image](https://user-images.githubusercontent.com/101063108/160775334-9a4b76e0-1da2-4f48-98b4-bce25d081958.png)

2ì°¨ì› ìœ„ì˜ ê³µê°„ì—ì„œ, ê° ì ë“¤ì„ ì‡ëŠ” ì„ ë¶„ë“¤ì´ ë¶„ë¦¬ë˜ì–´ ìˆì§€ ì•Šì€ ê²ƒì„ í™•ì¸ í•  ìˆ˜ ìˆë‹¤.

ì´ ì ë“¤ì„ 3ê°œì˜ ë³€ìˆ˜?ë¡œ ë§Œë“¤ì–´ì£¼ë©´, ìš°ë¦¬ëŠ” 3ì°¨ì› ê³µê°„ì—ì„œ ì´ ì ë“¤ì„ ë¶„ë¦¬í•´ì„œ í‘œí˜„í•  ìˆ˜ ìˆë‹¤.

ì´ëŸ¬í•œ ì›ë¦¬ë¥¼ ì´ìš©í•´ì„œ 3ì°¨, 4ì°¨,... 100ì°¨ í˜¹ì€ ê·¸ ì´ìƒë„ ê°€ëŠ¥í•  ê²ƒì´ë‹¤. ì´ëŸ° íŠ¹ì„± ê³µê°„ì´ ê³„ì† ì»¤ì§„ë‹¤ëŠ” ë‹¨ì ì´ ìˆë‹¤.

kernel ê³„ì‚°ì€ ë‹¤ë¥¸ ê³µê°„(ì°¨ì›)ì—ì„œ ë‘ê°œì˜ ë²¡í„°ë¥¼ ë‚´ì í•˜ëŠ” ê²ƒì´ë‹¤.

![image](https://user-images.githubusercontent.com/101063108/160776725-d1a5810c-151f-4d54-8d7e-ab06835793aa.png)

* polynomial(homogeneous)
* polynomial(inhomogeneous)
* Gaussian kernel function
* Hyperbolic tangent

polynomial kernel functionì˜ ê²½ìš°, ë‹¤ìŒì„ ë”°ë¥¸ë‹¤.

![image](https://user-images.githubusercontent.com/101063108/160777165-51e7bebc-a9c4-46c5-a35b-c1a008ad0834.png)

ì›ë³¸ ë²¡í„°ë“¤ì„ ë‹¤ë¥¸ ì°¨ì›ìœ¼ë¡œ ì˜®ê¸´ ë’¤, ë‚´ì í•˜ëŠ” ê²ƒê³¼ ë‚´ì ì„ í•œ ë’¤ ë‹¤ë¥¸ ì°¨ì›ì˜ ê³„ìˆ˜ë§Œí¼ ì œê³±í•´ì£¼ëŠ” ê²ƒì€ ê°™ì€ ê²°ê³¼ì„ì„ ì•Œ ìˆ˜ ìˆë‹¤.

ì´ë¥¼ ì´ìš©í•˜ë©´ ë§¤ìš° ë†’ì€ ì°¨ì›ìœ¼ë¡œ ì˜®ê¸°ê³  ë‚´ì í•˜ëŠ” kernelì„ ë‚´ì í•˜ê³  ì œê³± ê³„ì‚°ì„ í•´ì£¼ëŠ” ê²ƒìœ¼ë¡œ ê°„ë‹¨íˆ í•´ê²°í•  ìˆ˜ ìˆë‹¤.

# 5.9. SVM with Kernel


